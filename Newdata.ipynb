{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.6.0\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "\n",
    "from utils import utils_function\n",
    "from utils import calculate_descriptors\n",
    "from utils import generate_conformation\n",
    "from utils import generate_atom_input\n",
    "from utils import generate_monomer_input\n",
    "from utils import generate_peptide_input\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from model import model_utils\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Torch version: {torch.__version__}')\n",
    "print(f'Device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'config/CycPeptMP.json'\n",
    "config = json.load(open(config_path,'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example cyclic peptide drugs, without experimentally determined permeability.\n",
    "# Anidulafungin, Pasireotide\n",
    "new_data = pd.read_csv('data/new_data/new_data.csv')\n",
    "\n",
    "# Check duplicates\n",
    "old_data = pd.read_csv('data/CycPeptMPDB_Peptide_All.csv', low_memory=False)\n",
    "for i in range(len(new_data)):\n",
    "    if utils_function.canonicalize_smiles(new_data.iloc[i]['SMILES']) in old_data['SMILES'].to_list():\n",
    "        print(f'Your peptide: {i} ({new_data.iloc[i][\"ID_org\"]}) is already in the database.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Divide peptide into monomers (substructures)\n",
    "+ Divides __peptide bond__ and __ester bond__ in the __main chain__ and splits peptide into monomers.\n",
    "+ The cleaved amide group or O atom of the amide-to-ester substitution was methylated (addition of CH3), and the carboxyl group was converted to an aldehyde (addition of H).\n",
    "+ __Disulfide bond__ is not included in CycPeptMPDB data, but it may be better to consider it as a division target.\n",
    "+ __Bonds in side-chain__ are not subject to division to fully represent the side-chain properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique monomer list already exists.\n"
     ]
    }
   ],
   "source": [
    "# Save unique monomers\n",
    "utils_function.get_unique_monomer(new_data, 'data/new_data/unique_monomer.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Generate different peptide SMILES representations by SMILES enumeration as atom-level data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enumerated SMILES already exists.\n"
     ]
    }
   ],
   "source": [
    "utils_function.enumerate_smiles(new_data, config, 'data/new_data/enum_smiles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate 3D conformations for peptide and monomer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 120/120 [01:29<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [03:25<00:00,  1.71s/it]\n"
     ]
    }
   ],
   "source": [
    "# os.mkdir('sdf/new_data/')\n",
    "\n",
    "df_enu = pd.read_csv('data/new_data/enum_smiles.csv')\n",
    "\n",
    "# WARNING: If there is too much data, you can manually split it into multiple files for parallel computation.\n",
    "# For example:\n",
    "# sub_file_num = 10\n",
    "# sub_file_len = len(df_enu) // sub_file_num\n",
    "# for i in range(sub_file_num):\n",
    "#     df_enu.iloc[i*sub_file_len:(i+1)*sub_file_len].to_csv(f'sdf/new_data/peptide_{i}.csv', index=False)\n",
    "\n",
    "generate_conformation.generate_peptide_conformation(config, df_enu, 'sdf/new_data/peptide.sdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Monomer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:20<00:00,  1.91s/it]\n"
     ]
    }
   ],
   "source": [
    "df_monomer = pd.read_csv('data/new_data/unique_monomer.csv')\n",
    "generate_conformation.generate_monomer_conformation(config, df_monomer, 'sdf/new_data/monomer.sdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Calculate 2D and 3D descriptors for peptide and monomer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. RDKit (208 types 2D descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDKit descriptors already exists.\n"
     ]
    }
   ],
   "source": [
    "# peptide\n",
    "calculate_descriptors.calc_rdkit_descriptors(new_data['SMILES'].tolist(), 'desc/new_data/peptide_rdkit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDKit descriptors already exists.\n"
     ]
    }
   ],
   "source": [
    "# monomer\n",
    "calculate_descriptors.calc_rdkit_descriptors(df_monomer['SMILES'].tolist(), 'desc/new_data/monomer_rdkit.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Mordred (1275 types 2D descriptors + 51 types 3D descriptors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mordred 2D descriptors already exists.\n"
     ]
    }
   ],
   "source": [
    "# peptide\n",
    "calculate_descriptors.calc_mordred_2Ddescriptors(new_data['SMILES'].tolist(), 'desc/new_data/peptide_mordred_2D.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mordred 2D descriptors already exists.\n"
     ]
    }
   ],
   "source": [
    "# monomer\n",
    "calculate_descriptors.calc_mordred_2Ddescriptors(df_monomer['SMILES'].tolist(), 'desc/new_data/monomer_mordred_2D.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mordred 3D descriptors already exists.\n"
     ]
    }
   ],
   "source": [
    "# peptide\n",
    "mols = Chem.SDMolSupplier('sdf/new_data/peptide.sdf')\n",
    "calculate_descriptors.calc_mordred_3Ddescriptors(mols, 'desc/new_data/peptide_mordred_3D.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mordred 3D descriptors already exists.\n"
     ]
    }
   ],
   "source": [
    "# monomer\n",
    "mols = Chem.SDMolSupplier('sdf/new_data/monomer.sdf')\n",
    "calculate_descriptors.calc_mordred_3Ddescriptors(mols, 'desc/new_data/monomer_mordred_3D.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. MOE (206 types 2D descriptors + 117 types 3D descriptors)\n",
    "+ CycPeptMP used the commercial software __MOE__ to calculate some of the descriptors.\n",
    "+ In particular, many of the selected 3D descriptors were computed by MOE.\n",
    "+ Please manualy calculate these descriptors. I showed __utils/MOE_3D_descriptors.sh__ as an example.\n",
    "+ For 2D descriptors:\n",
    "    + Please wash SMILES and use washed mols for calculation.\n",
    "        + for GUI: Molecule -> Wash -> Protonation: Dominant\n",
    "+ For 3D descriptors:\n",
    "    + First, please calculate the charge for the RDKit conformations.\n",
    "        + for GUI: Compute -> Molecule -> Partial Charges\n",
    "    + 21 MOPAC descriptors of the 3D descriptors were not computed due to computational cost (AM_x, MNDO_, PM3_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4. Concatenation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_descriptors.merge_descriptors(config, 'desc/new_data/', 'data/new_data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Generate input for three sub-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'model/input/new_data/'\n",
    "set_name = 'new'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Atom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 120/120 [00:00<00:00, 1573.61it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 120/120 [00:00<00:00, 823.57it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 120/120 [00:00<00:00, 1099.35it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 120/120 [00:00<00:00, 852.99it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 120/120 [00:00<00:00, 1091.73it/s]\n"
     ]
    }
   ],
   "source": [
    "df_enu = pd.read_csv('data/new_data/enum_smiles.csv')\n",
    "mols = Chem.SDMolSupplier('sdf/new_data/peptide.sdf')\n",
    "\n",
    "generate_atom_input.generate_atom_input(config, new_data, df_enu, mols, folder_path, set_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Monomer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pyw/Software/GitHub/cycpeptmp-modified/utils/generate_monomer_input.py:19: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  sequence = df.filter(regex='Substructure-\\d+', axis=1).values\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['density', 'logP(o/w)', 'lip_violation', 'h_logD'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m df_mono_2D = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mdesc/new_data/monomer_2D.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m df_mono_3D = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mdesc/new_data/monomer_3D.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m generate_monomer_input.generate_monomer_input(config, new_data, df_mono_2D, df_mono_3D, folder_path, set_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Software/GitHub/cycpeptmp-modified/utils/generate_monomer_input.py:115\u001b[39m, in \u001b[36mgenerate_monomer_input\u001b[39m\u001b[34m(config, df, df_mono_2D, df_mono_3D, folder_path, set_name)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;66;03m# Standardize monomer descriptors by Z-score\u001b[39;00m\n\u001b[32m    114\u001b[39m df_mono = pd.concat([df_mono_2D.iloc[\u001b[38;5;28msum\u001b[39m([[_]*REPLICA_NUM \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df_mono_2D))], [])].reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m), df_mono_3D], axis=\u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m desc_preprocessing = df_mono[use_descriptors].copy()\n\u001b[32m    116\u001b[39m mono_desc_mean = config[\u001b[33m'\u001b[39m\u001b[33mdescriptor\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mmono_desc_mean\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    117\u001b[39m mono_desc_std = config[\u001b[33m'\u001b[39m\u001b[33mdescriptor\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mmono_desc_std\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ML/lib/python3.12/site-packages/pandas/core/frame.py:4108\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4107\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4108\u001b[39m     indexer = \u001b[38;5;28mself\u001b[39m.columns._get_indexer_strict(key, \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[32m1\u001b[39m]\n\u001b[32m   4110\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ML/lib/python3.12/site-packages/pandas/core/indexes/base.py:6200\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6198\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6200\u001b[39m \u001b[38;5;28mself\u001b[39m._raise_if_missing(keyarr, indexer, axis_name)\n\u001b[32m   6202\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6204\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ML/lib/python3.12/site-packages/pandas/core/indexes/base.py:6252\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6249\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6251\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6252\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['density', 'logP(o/w)', 'lip_violation', 'h_logD'] not in index\""
     ]
    }
   ],
   "source": [
    "df_mono_2D = pd.read_csv('desc/new_data/monomer_2D.csv')\n",
    "df_mono_3D = pd.read_csv('desc/new_data/monomer_3D.csv')\n",
    "\n",
    "generate_monomer_input.generate_monomer_input(config, new_data, df_mono_2D, df_mono_3D, folder_path, set_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Peptide model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 2007.32it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1003.30it/s]\n"
     ]
    }
   ],
   "source": [
    "df_pep_2D = pd.read_csv('desc/new_data/peptide_2D.csv')\n",
    "df_pep_3D = pd.read_csv('desc/new_data/peptide_3D.csv')\n",
    "df_enu = pd.read_csv('data/new_data/enum_smiles.csv')\n",
    "\n",
    "generate_peptide_input.generate_peptide_input(config, new_data, df_enu, df_pep_2D, df_pep_3D, folder_path, set_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 30])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([16])\n",
      "torch.Size([2048])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "MODEL_TYPE = 'Fusion'\n",
    "# OPTIMIZE: Augmentation times\n",
    "REPLICA_NUM = 60\n",
    "\n",
    "# Import input\n",
    "set_name = 'new'\n",
    "dataset_new = model_utils.load_dataset('model/input/new_data/', MODEL_TYPE, REPLICA_NUM, set_name)\n",
    "\n",
    "for _ in dataset_new[0]:\n",
    "    print(_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "seed = config['data']['seed']\n",
    "model_utils.set_seed(seed)\n",
    "\n",
    "# Determined hyperparameters\n",
    "best_trial = config['model']\n",
    "\n",
    "for cv in range(3):\n",
    "    # Load trained weights\n",
    "    model_path = f'weight/{MODEL_TYPE}/{MODEL_TYPE}-{REPLICA_NUM}_cv{cv}.cpt'\n",
    "    checkpoint = torch.load(model_path)\n",
    "    model = model_utils.create_model(best_trial, DEVICE, config['model']['use_auxiliary'])\n",
    "    model_state = checkpoint['model_state_dict']\n",
    "    model.load_state_dict(model_state)\n",
    "    model = nn.DataParallel(model)\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    # OPTIMIZE: Batch size\n",
    "    batch_size = len(dataset_new)\n",
    "    dataloader_now = torch.utils.data.DataLoader(dataset_new, batch_size=batch_size, shuffle=False)\n",
    "    ids, exps, preds = model_utils.predict_valid(DEVICE, model, dataloader_now, None, istrain=False,\n",
    "                                                 use_auxiliary=config['model']['use_auxiliary'], gamma_layer=config['model']['gamma_layer'], gamma_subout=config['model']['gamma_subout'])\n",
    "    now_pred = pd.DataFrame(preds, columns=['pred'])\n",
    "    now_pred['exp'] = exps\n",
    "    now_pred['ID'] = ids\n",
    "\n",
    "    # NOTE: Can save all predicted values of all replicas\n",
    "    # now_pred.to_csv(f'predicted/{MODEL_TYPE}-{REPLICA_NUM}/{set_name}_cv{cv}_allrep.csv')\n",
    "\n",
    "    # Take the average of all replicas\n",
    "    now_pred = now_pred.groupby('ID').mean()\n",
    "    now_pred.to_csv(f'predicted/new_data/{MODEL_TYPE}-{REPLICA_NUM}/{set_name}_cv{cv}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.788538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-7.024245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID      pred\n",
       "0  1.0 -6.788538\n",
       "1  2.0 -7.024245"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_cv0 = pd.read_csv(f'predicted/new_data/{MODEL_TYPE}-{REPLICA_NUM}/{set_name}_cv0.csv')\n",
    "pred_cv1 = pd.read_csv(f'predicted/new_data/{MODEL_TYPE}-{REPLICA_NUM}/{set_name}_cv1.csv')\n",
    "pred_cv2 = pd.read_csv(f'predicted/new_data/{MODEL_TYPE}-{REPLICA_NUM}/{set_name}_cv2.csv')\n",
    "\n",
    "pred_mean = (pred_cv0 + pred_cv1 + pred_cv2) / 3\n",
    "pred_mean[['ID', 'pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
